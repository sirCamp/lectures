{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed ML\n",
    "\n",
    "The Randomized search is a common technique used to figuring out the best set of paramters of a machine learning algorithm. This process is really slow at take long time to finish, specially when the algorithm have a lot of parameters to tune. The process iterates several times with different paramters combinations in order to retrieve the best combination. Each iteration is executed from 3 to 5 times in order to have the best empirical evidences of the results.\n",
    "Even tough the process is slow,  fortunately, we can use a cluster to speed up it, let's see how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.externals.joblib import parallel_backend\n",
    "from dask.distributed import Client\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dummy dataset composed by 1000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('192.168.9.30:8786')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined the set of the possibile paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,200), (100,100,100)],\n",
    "    'activation': ['tanh', 'relu','logistic'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter':[50, 100,200,1000, 2000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined the process with 15 iterations and 3 trainings for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with parallel_backend('dask'):\n",
    "    random_search = RandomizedSearchCV(\n",
    "                MLPClassifier(),\n",
    "                param_distributions=parameters,\n",
    "                n_iter=15,\n",
    "                cv=3,\n",
    "                n_jobs=-1,\n",
    "                verbose=1\n",
    "            )\n",
    "    random_search.fit(X, y)\n",
    "    print('Best score obtained: {0}'.format(random_search.best_score_))\n",
    "    print('Parameters:')\n",
    "    params = \"\"\n",
    "    for param, value in random_search.best_params_.items():\n",
    "        print('\\t{}: {}'.format(param, value))\n",
    "        params += '\\t{}: {}'.format(param, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try by yourself to change the parameters of the neural network [MLPClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), check all available parameters and try how the training change in the cluster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to change how change the speed of the execution by change the cluster configuration. Try to stop the scheduler and the workers, than re-start both and change how the execution time decrease by changing the ```--nprocs numofworkers``` parameter of ```dask-worker``` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
