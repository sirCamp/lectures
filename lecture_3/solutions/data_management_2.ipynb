{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts of MapReduce in Dask\n",
    "\n",
    "### What is MapReduce?\n",
    "\n",
    "MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster. [Wikipedia](https://en.wikipedia.org/wiki/MapReduce)\n",
    "\n",
    "\n",
    "\n",
    "A MapReduce program is composed of a map procedure (or method), which performs filtering, sorting or element elaborations (such as sorting out students by first name, one queue for each name), and a reduce method, which performs a summary operation (such as counting the number of students in each queue, yielding name frequencies). The MapReduce  frameowork it's essential when you have big data problems and a cluster.\n",
    "It's realiable and fault tolerant and allows to work on huge data (Exabyte) on a cluster without memory issues.\n",
    "\n",
    "The model is a specialization version of the ```split-apply-combine``` approache for data analysis. Each action of the map or reduce function is made on a partition of data with an indipendet process.\n",
    "Each worker of a cluster execute the same operations on separated chunks of data. Once the computation is terminated the results are retrieved from each worker node and then they are combined toghter. If necessary the map-reduce function are applied again on the results combination. This process is repeated until all the operations are done and all the results are merge into single one which is the real final results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example of the Map function. Try to convert the ```CRSDepTime``` column to a timestamp. In the dataset the CRSDepTime which is a timestamps as HHMM, it is stored as integers in the csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1055\n",
       "1    1055\n",
       "2    1055\n",
       "3    1729\n",
       "4    1729\n",
       "5    1729\n",
       "6    1729\n",
       "7    1729\n",
       "8    1729\n",
       "9    1729\n",
       "Name: CRSDepTime, dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv(os.path.join('data', 'nycflights', '*.csv'),\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': str,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})\n",
    "\n",
    "\n",
    "\n",
    "crs_dep_time = df.CRSDepTime.head(10)\n",
    "crs_dep_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to convert these to timestamps of scheduled departure time, we need to convert these integers into ```pd.Timedelta``` objects, and then combine them with the ```Date``` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 3 µs, total: 8 µs\n",
      "Wall time: 20 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   1993-01-29 10:55:00\n",
       "1   1993-01-30 10:55:00\n",
       "2   1993-01-31 10:55:00\n",
       "3   1993-01-03 17:29:00\n",
       "4   1993-01-04 17:29:00\n",
       "5   1993-01-05 17:29:00\n",
       "6   1993-01-06 17:29:00\n",
       "7   1993-01-07 17:29:00\n",
       "8   1993-01-08 17:29:00\n",
       "9   1993-01-10 17:29:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "import pandas as pd\n",
    "\n",
    "# Get the first 10 dates to complement our `crs_dep_time`\n",
    "date = df.Date.head(10)\n",
    "\n",
    "# Get hours as an integer, convert to a timedelta\n",
    "hours = crs_dep_time // 100\n",
    "hours_timedelta = pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "# Get minutes as an integer, convert to a timedelta\n",
    "minutes = crs_dep_time % 100\n",
    "minutes_timedelta = pd.to_timedelta(minutes, unit='m')\n",
    "\n",
    "# Apply the timedeltas to offset the dates by the departure time\n",
    "departure_timestamp = date + hours_timedelta + minutes_timedelta\n",
    "departure_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with the MapReduce.\n",
    "Dask.dataframe provides a few methods to make applying custom functions to Dask DataFrames easier:\n",
    "\n",
    "+ map_partitions\n",
    "+ map_overlap\n",
    "+ reduction\n",
    "Here we'll just be discussing map_partitions, which we can use to implement to_timedelta on our own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 2 µs, total: 4 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "hours = df.CRSDepTime // 100\n",
    "# hours_timedelta = pd.to_timedelta(hours, unit='h')\n",
    "hours_timedelta = hours.map_partitions(pd.to_timedelta, unit='h')\n",
    "\n",
    "minutes = df.CRSDepTime % 100\n",
    "# minutes_timedelta = pd.to_timedelta(minutes, unit='m')\n",
    "minutes_timedelta = minutes.map_partitions(pd.to_timedelta, unit='m')\n",
    "\n",
    "departure_timestamp = df.Date + hours_timedelta + minutes_timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=4\n",
       "    datetime64[ns]\n",
       "               ...\n",
       "               ...\n",
       "               ...\n",
       "               ...\n",
       "dtype: datetime64[ns]\n",
       "Dask Name: add, 44 tasks"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departure_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1993-01-29 10:55:00\n",
       "1   1993-01-30 10:55:00\n",
       "2   1993-01-31 10:55:00\n",
       "3   1993-01-03 17:29:00\n",
       "4   1993-01-04 17:29:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departure_timestamp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise1: \n",
    "Try to rewrite the above code to use a single call to map_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_departure_timestamp(df):\n",
    "    #write your code here \n",
    "    hours = df.CRSDepTime // 100\n",
    "    hours_timedelta = pd.to_timedelta(hours, unit='h')\n",
    "\n",
    "    minutes = df.CRSDepTime % 100\n",
    "    minutes_timedelta = pd.to_timedelta(minutes, unit='m')\n",
    "\n",
    "    return df.Date + hours_timedelta + minutes_timedelta\n",
    "\n",
    "    departure_timestamp = df.map_partitions(compute_departure_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "departure_timestamp = df.map_partitions(compute_departure_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1993-01-29 10:55:00\n",
       "1   1993-01-30 10:55:00\n",
       "2   1993-01-31 10:55:00\n",
       "3   1993-01-03 17:29:00\n",
       "4   1993-01-04 17:29:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departure_timestamp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
