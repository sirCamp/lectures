{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Deep Learning on CPU-GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Deep Learning?\n",
    "Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost. It is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. Itâ€™s achieving results that were not possible before.\n",
    "\n",
    "In deep learning, a computer model learns to perform classification tasks directly from images, text, or sound. Deep learning models can achieve state-of-the-art accuracy, sometimes exceeding human-level performance. Models are trained by using a large set of labeled data and neural network architectures that contain many layers.\n",
    "\n",
    "### Awesome! But more in detail?\n",
    "Deep Learning is a subfield of Artificial Intelligence and then of Machine learning concerned with algorithms inspired by the structure and function of the brain called artificial neural networks.\n",
    "The *Deep* stays for *Deep Neural Network*. \n",
    "In other words the Deep learning is a Machine learning area where neural networks are composed by *stacked layers of neurons of different types*\n",
    "\n",
    "Due to Deep learning is inspired to the brain, Deep learning Neural Network have different type. \n",
    "The most common are:\n",
    "\n",
    "+ Dense Neural Network (evolution of MLP classifier)\n",
    "+ Convolutional Neural Network ( mainly used for vision/recognition purposes, they emulate the visual brain cortex)\n",
    "+ Recurrent Neural Network (mainly used for timeseries forcasting, text / audio elaboration)\n",
    "\n",
    "Deep Neural Network works fine with clustering because, due to their computation complexity, they are specifically designed for parallel computation (CPU/ GPU with CUDA) and distrbuted computing since they are implemented as graph.\n",
    "\n",
    "Unfortunately today we will see only how to distribute the computation over a cluster with CPU since there aren't available GPUs on the lab.\n",
    "Anyway, to work with CUDA on your PC, it's sufficient to install CUDA and the package tensorflow-gpu in a propper way.\n",
    "Drop me an email if you'd like to install it at home: [stefano.campese@omnys.com](stefano.campese@omnys.com)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to work with Distributed Deep learning ?\n",
    "\n",
    "In order to work in a simple way with clustering and deep lerning three packages are necessary:\n",
    "+ Tensorflow\n",
    "+ Keras\n",
    "+ Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Tensorflow?\n",
    "\n",
    "TensorFlow is an open source software library for numerical computation using data-flow graphs. It was originally developed by the Google Brain Team within Google's Machine Intelligence research organization for machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as wel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Keras?\n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "\n",
    "Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "Runs seamlessly on CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, Let's see how to create simple Distributed Deep Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dask_ml.datasets import make_classification\n",
    "\n",
    "client = Client('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_tensorflow import start_tensorflow\n",
    "tf_spec, dask_spec = start_tensorflow(client, ps=2, worker=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=6000, n_features=22, random_state=42, chunks=1000)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_neural_network():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_shape=(22,), kernel_initializer='normal', activation='relu')) #layer 1 with 60 neurons\n",
    "    model.add(Dense(30, kernel_initializer='normal', activation='relu')) #layer 2 with 30 neurons\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid')) #layer 3 with 1 neuron (binary classification)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = build_deep_neural_network()\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=1)\n",
    "scores = model.evaluate(X_test,y_test, verbose=1)\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to look the cluster dashboard! Take a look to the Graph tab!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mushrooms recognition: poisonous or edible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('https://www.dropbox.com/s/7u3lm737ogbqsg8/mushrooms_categorized.csv?dl=1')\n",
    "\n",
    "df = df.repartition(npartitions=4)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['class'].values.compute()#to_dask_array(lengths=True)\n",
    "X = df[df.columns.difference(['class'])].values.compute()#.to_dask_array(lengths=True)\n",
    "print(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_neural_network():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(22,)))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dropout\n",
    "model = build_deep_neural_network()\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=10, batch_size=64)\n",
    "print(model.predict(X_test))\n",
    "scores = model.evaluate(X_test,y_test, verbose=1)\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog or Cat?\n",
    "\n",
    "Let's try to predict if an image is a cat or a dog! Let's try with a Dense Deep Network.\n",
    "At first load the remote dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df = dd.read_csv('https://www.dropbox.com/s/lo8hmhczoo6c7yo/dogs_and_cats.csv?dl=1')\n",
    "\n",
    "y = df['label'].values.compute()#to_dask_array(lengths=True)\n",
    "X = df[df.columns.difference(['label'])].values.compute()#.to_dask_array(lengths=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_deep_neural_network():\n",
    "    # create model\n",
    "    model.add(Dense(1024, activation='relu', input_shape=(12288,)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dropout\n",
    "model = build_deep_neural_network()\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=10, batch_size=32)\n",
    "print(model.predict(X_test))\n",
    "scores = model.evaluate(X_test,y_test, verbose=1)\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy seems not good! Let's try to use the *Convolutional Neural Network*.\n",
    "Before to start to work with those network, it's necessary to reshape the data to their original form.\n",
    "Convolutional Neural Network, in fact, work on multidimensional data. Since the orginal dataset contains the data of dogs and cat image encoded in a monodimensional array, to work properly with these network we have to reshape each element in its original form: 64x64x3, where 64x64 is the resolution and 3 stands for the RGB encoding (in other word the image is coloured and not in grayscale).\n",
    "\n",
    "Hence, let's start: reshape the images in the right way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train.reshape((len(X_train), 64,64, 3)),  X_test.reshape((len(X_test), 64,64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import Flatten\n",
    "def build_deep_cnn_neural_network():\n",
    "    # create model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, kernel_size=(3,3), name='c', strides=(1, 1), padding='valid', activation='relu', input_shape=(64,64,3)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu', name='d'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu', name='d1'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', name='d2'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dropout\n",
    "model = build_deep_cnn_neural_network()\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=10, batch_size=32)\n",
    "print(model.predict(X_test))\n",
    "scores = model.evaluate(X_test,y_test, verbose=1)\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Take the first implementation of \"dog or cat\", scale the features with the MinMaxScaler with features range in -1, 1 and then re-run all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "df = dd.read_csv('https://www.dropbox.com/s/lo8hmhczoo6c7yo/dogs_and_cats.csv?dl=1')\n",
    "\n",
    "y = df['label'].values.compute()\n",
    "X = df[df.columns.difference(['label'])].values.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1)) #put your code here\n",
    "\n",
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2, train_size=0.8)\n",
    "\n",
    "scaler = scaler.fit(X_train) #put your code here\n",
    "X_train = scaler.transform(X_train) #put your code here \n",
    "X_test = scaler.transform(X_test) #put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(12288,)))\n",
    "model.add(Dense(64, activation='relu', name='d'))\n",
    "model.add(Dense(32, activation='relu', name='d1'))\n",
    "model.add(Dense(1, activation='sigmoid', name='d2'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=10, batch_size=32, validation_split=0.1) #pur your code here\n",
    "scores = model.evaluate(X_test,y_test, verbose=1) #put your code here\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is it happened?\n",
    "Comment the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to predic the X_train and see what happens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train,y_train, verbose=1) #put your code here\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phenomeon is called overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Take the second implementation of \"dog or cat\", double the covolutional layer, scale the features with the MinMaxScaler and then re-run all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()#put your code here\n",
    "\n",
    "from dask_ml.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2, train_size=0.8)\n",
    "\n",
    "scaler = scaler.fit(X_train) #put your code here\n",
    "X_train = scaler.transform(X_train) #put your code here \n",
    "X_test = scaler.transform(X_test) #put your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), name='c', strides=(1, 1), padding='valid', activation='relu', input_shape=(64,64,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), name='c1', strides=(1, 1), padding='valid', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu', name='d'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu', name='d1'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', name='d2'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test = X_train.reshape((len(X_train), 64,64, 3)),  X_test.reshape((len(X_test), 64,64, 3))\n",
    "\n",
    "model.fit(X_train, y_train, verbose=1, epochs=10, batch_size=32, validation_split=0.1) #pur your code here\n",
    "scores = model.evaluate(X_test,y_test, verbose=1) #put your code here\n",
    "print(\"Accuracy: \"+str(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
